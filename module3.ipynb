{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f5f4a5c-0a4d-461b-8ebd-ab097bf8a549",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:2.4em;color:green;\"> Advanced Encoding Techniques </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ac998c-6877-4a6a-bfbf-95bf9ed2dd56",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:1.4em;\"> Two kinds of categorical data-\n",
    "\n",
    " </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88999a8-b942-4a79-b942-a46cde44b73d",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:1.4em;\"> 1 .Ordinal Data: One category is greater than the other in some sense. For example locations like \"TIER-1\" , TIER-2\" so Tier-1>Tier-2 in some sense of rank of cities  </p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705f3dc4-7add-499b-bef8-1196bcd72bef",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:1.4em;\">2. Nominal Data: worry about just the presence or absence of a feature. For example city name in which a person lives. It is equal if a person lives in Delhi or Bangalore </p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abfa9ff-6904-49ae-8fcd-f0557e4f7afc",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:2.4em;color:green;\"> Various Techniques </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd115f3-3b3d-49fd-9629-5ef55132ca3d",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:1.4em;color:green;\"> 1. Label Encoding or Ordinal Encoding. Use this when the categorical feature is ordinal </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66d31575-6b9f-4898-a80f-35657f292375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Degree\n",
      "0  High school\n",
      "1      Masters\n",
      "2      Diploma\n",
      "3    Bachelors\n",
      "4    Bachelors\n",
      "5      Masters\n",
      "6          Phd\n",
      "7  High school\n",
      "8  High school\n",
      "   Degree\n",
      "0       1\n",
      "1       4\n",
      "2       2\n",
      "3       3\n",
      "4       3\n",
      "5       4\n",
      "6       5\n",
      "7       1\n",
      "8       1\n"
     ]
    }
   ],
   "source": [
    "import category_encoders as ce\n",
    "import pandas as pd\n",
    "train_df=pd.DataFrame({'Degree':['High school','Masters','Diploma','Bachelors','Bachelors','Masters','Phd','High school','High school']})\n",
    "\n",
    "# create object of Ordinalencoding\n",
    "encoder= ce.OrdinalEncoder(cols=['Degree'],return_df=True,\n",
    "                           mapping=[{'col':'Degree',\n",
    "'mapping':{'High school':1,'Diploma':2,'Bachelors':3,'Masters':4,'Phd':5}}])\n",
    "\n",
    "#Original data\n",
    "print(train_df)\n",
    "\n",
    "df_train_transformed = encoder.fit_transform(train_df)\n",
    "#Encoded Data\n",
    "print(df_train_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae4cd41-8ea4-466d-a56c-4cbedb4791f5",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:1.4em;color:green;\">2. One Hot Encoding. Use this when the features are nominal </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "79c73094-aeac-46b5-84c6-26da1de5c787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        City\n",
      "0    Lucknow\n",
      "1     Kanpur\n",
      "2      Noida\n",
      "3   Amritsar\n",
      "4  Sultanpur\n",
      "5    Lucknow\n",
      "6      Noida\n",
      "7  Sultanpur\n",
      "8    Lucknow\n",
      "   City_Lucknow  City_Kanpur  City_Noida  City_Amritsar  City_Sultanpur\n",
      "0             1            0           0              0               0\n",
      "1             0            1           0              0               0\n",
      "2             0            0           1              0               0\n",
      "3             0            0           0              1               0\n",
      "4             0            0           0              0               1\n",
      "5             1            0           0              0               0\n",
      "6             0            0           1              0               0\n",
      "7             0            0           0              0               1\n",
      "8             1            0           0              0               0\n"
     ]
    }
   ],
   "source": [
    "import category_encoders as ce\n",
    "import pandas as pd\n",
    "data=pd.DataFrame({'City':[\n",
    "'Lucknow','Kanpur','Noida','Amritsar','Sultanpur','Lucknow','Noida','Sultanpur','Lucknow'\n",
    "]})\n",
    "\n",
    "#Create object for one-hot encoding\n",
    "encoder=ce.OneHotEncoder(cols='City',return_df=True,use_cat_names=True)\n",
    "\n",
    "#Original Data\n",
    "print(data)\n",
    "\n",
    "data_encoded = encoder.fit_transform(data)\n",
    "#Encoded Data\n",
    "print(data_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a08fc89-af3a-4dbb-9e59-ad2b3ce5b548",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:1.4em;color:green;\">3. Dummy Encoding. Similar to one-hot encoding.Dummy encoding uses N-1 features to represent N labels/categories.Notice one of the category is just represented using all zero's </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0706bfa6-41e6-4062-9c28-36088cf95461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        City\n",
      "0    Lucknow\n",
      "1     Kanpur\n",
      "2      Noida\n",
      "3   Amritsar\n",
      "4  Sultanpur\n",
      "5    Lucknow\n",
      "6      Noida\n",
      "7  Sultanpur\n",
      "8    Lucknow\n",
      "   City_Kanpur  City_Lucknow  City_Noida  City_Sultanpur\n",
      "0            0             1           0               0\n",
      "1            1             0           0               0\n",
      "2            0             0           1               0\n",
      "3            0             0           0               0\n",
      "4            0             0           0               1\n",
      "5            0             1           0               0\n",
      "6            0             0           1               0\n",
      "7            0             0           0               1\n",
      "8            0             1           0               0\n"
     ]
    }
   ],
   "source": [
    "import category_encoders as ce\n",
    "import pandas as pd\n",
    "data=pd.DataFrame({'City':['Lucknow','Kanpur','Noida','Amritsar','Sultanpur','Lucknow','Noida','Sultanpur','Lucknow']})\n",
    "\n",
    "#Original Data\n",
    "print(data)\n",
    "                           \n",
    "data_encoded=pd.get_dummies(data=data,drop_first=True)\n",
    "#Encoded Data                           \n",
    "print(data_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10e2950-1d51-4e2a-b339-7a72322ed904",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:1.4em;color:green;\">4. Drawbacks of one hot , dummy encodings. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d8b7ba-0b5a-4ed6-a7c1-91cdda2e79a1",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:1.4em;\"> Due to the massive increase in the dataset, coding slows down the learning of the model along with deteriorating the overall performance that ultimately makes the model computationally expensive. Further, while using tree-based models these encodings are not an optimum choice. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a427b86-7c3d-401d-8391-5e8270194f26",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:1.4em;color:green;\">5. Hash Encoder. Here, the user can fix the number of dimensions after transformation using n_component argument. so â€“ A feature with 50 categories can be represented using N new features similarly, a feature with 1000 categories can also be transformed using N new features. Hashing encoders have been very successful if the dataset has high cardinality features meaning columns with values that are very uncommon or unique</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fec3ebf8-b08e-402e-b504-0a9c88aa8c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   col_0  col_1  col_2  col_3  col_4  col_5\n",
      "0      0      0      0      0      1      0\n",
      "1      0      0      0      1      0      0\n",
      "2      0      0      0      0      1      0\n",
      "3      0      0      0      1      0      0\n",
      "4      0      0      0      1      0      0\n",
      "5      0      1      0      0      0      0\n",
      "6      1      0      0      0      0      0\n",
      "7      0      1      0      0      0      0\n",
      "8      0      0      0      0      1      0\n"
     ]
    }
   ],
   "source": [
    "import category_encoders as ce\n",
    "import pandas as pd\n",
    "\n",
    "#Create the dataframe\n",
    "data=pd.DataFrame({'Month':['January','April','March','April','Februay','June','July','June','September']})\n",
    "\n",
    "#Create object for hash encoder\n",
    "encoder=ce.HashingEncoder(cols='Month',n_components=6)\n",
    "\n",
    "data_encoded = encoder.fit_transform(data)\n",
    "#Encoded Data\n",
    "print(data_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82cc531-0b53-48fd-aad5-391f5c9991b3",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:1.4em;color:green;\"> 6. Drawbacks of Hash Encoder </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bb7bd8-1340-4d29-a256-9b09bc768e4d",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:1.4em;\">1 Hashing transforms the data in lesser dimensions, it may lead to loss of information </p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731f068b-4b6a-48b8-a918-3e24ce192c72",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:1.4em;\">2. Large number of features are depicted into lesser dimensions, hence multiple values can be represented by the same hash value, this is known as a collision</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36c47da-6a7a-4120-95ea-613a7f3749f1",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:1.4em;color:green;\">7. Binary Encoding. Combination of Hash encoding and ordinal encoding.Categorical feature is first converted into numerical using an ordinal encoder. Then the numbers are transformed in the binary number. At the end binary value is split into different columns. It is a Memory-efficient encoding scheme and also takes care of collison issue. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "83626168-5845-4a4f-aabf-39312df4270e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        City\n",
      "0    Lucknow\n",
      "1     Kanpur\n",
      "2      Noida\n",
      "3   Amritsar\n",
      "4  Sultanpur\n",
      "5    Lucknow\n",
      "6      Noida\n",
      "7  Sultanpur\n",
      "8    Lucknow\n",
      "   City_0  City_1  City_2\n",
      "0       0       0       1\n",
      "1       0       1       0\n",
      "2       0       1       1\n",
      "3       1       0       0\n",
      "4       1       0       1\n",
      "5       0       0       1\n",
      "6       0       1       1\n",
      "7       1       0       1\n",
      "8       0       0       1\n"
     ]
    }
   ],
   "source": [
    "import category_encoders as ce\n",
    "import pandas as pd\n",
    "\n",
    "#Create the Dataframe\n",
    "data=pd.DataFrame({'City':['Lucknow','Kanpur','Noida','Amritsar','Sultanpur','Lucknow','Noida','Sultanpur','Lucknow']})\n",
    "\n",
    "#Create object for binary encoding\n",
    "encoder= ce.BinaryEncoder(cols=['City'],return_df=True)\n",
    "\n",
    "#Original Data\n",
    "print(data)\n",
    "\n",
    "data_encoded=encoder.fit_transform(data) \n",
    "#Encoded Data\n",
    "print(data_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5704f5f-2e82-43a5-8e47-72498adaa7a5",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:1.4em;color:green;\"> Base N Encoding. In the case when categories are more and binary encoding is not able to handle the dimensionality then we can use a larger base such as 4 or 8. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b2d915ea-3e36-4b3a-9570-abd13ba60df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        City\n",
      "0      Delhi\n",
      "1     Mumbai\n",
      "2  Hyderabad\n",
      "3    Chennai\n",
      "4  Bangalore\n",
      "5      Delhi\n",
      "6  Hyderabad\n",
      "7     Mumbai\n",
      "8       Agra\n",
      "   City_0  City_1\n",
      "0       0       1\n",
      "1       0       2\n",
      "2       0       3\n",
      "3       0       4\n",
      "4       1       0\n",
      "5       0       1\n",
      "6       0       3\n",
      "7       0       2\n",
      "8       1       1\n"
     ]
    }
   ],
   "source": [
    "import category_encoders as ce\n",
    "import pandas as pd\n",
    "\n",
    "#Create the dataframe\n",
    "data=pd.DataFrame({'City':['Delhi','Mumbai','Hyderabad','Chennai','Bangalore','Delhi','Hyderabad','Mumbai','Agra']})\n",
    "\n",
    "#Create an object for Base N Encoding\n",
    "encoder= ce.BaseNEncoder(cols=['City'],return_df=True,base=5)\n",
    "\n",
    "#Original Data\n",
    "print(data)\n",
    "\n",
    "data_encoded=encoder.fit_transform(data)\n",
    "#Encoded Data\n",
    "print(data_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63711cb-7ba3-423f-9e85-489c6e695335",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
